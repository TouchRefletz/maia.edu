name: Manual Upload (Sync to HF)

on:
  repository_dispatch:
    types: [manual-upload]
  workflow_dispatch:
    inputs:
      slug:
        description: 'Slug for folder name (e.g. "enem-2023")'
        required: true
      pdf_url:
        description: "Temporary URL for the PDF"
        required: true
      gabarito_url:
        description: "Temporary URL for the Answer Key"
        required: false
      title:
        description: "Exam Title"
        required: true
      year:
        description: "Exam Year"
        required: true
      institution:
        description: "Institution Name"
        required: true
      phase:
        description: "Phase"
        required: true
      source_url_prova:
        description: "Original Source URL for Proof"
        required: false
      source_url_gabarito:
        description: "Original Source URL for Answer Key"
        required: false

jobs:
  sync:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Setup Logger
        run: |
          cat << 'EOF' > logger.py
          import sys
          import time
          import json
          import hashlib
          import hmac
          import os
          import http.client
          import urllib.parse

          # --- CONFIG ---
          PUSHER_APP_ID = os.environ.get("PUSHER_APP_ID")
          PUSHER_KEY = os.environ.get("PUSHER_KEY")
          PUSHER_SECRET = os.environ.get("PUSHER_SECRET")
          PUSHER_CLUSTER = os.environ.get("PUSHER_CLUSTER")
          CHANNEL = os.environ.get("SLUG") # Using slug as channel

          def send_to_pusher(event_name, data_payload):
              if not all([PUSHER_APP_ID, PUSHER_KEY, PUSHER_SECRET, PUSHER_CLUSTER, CHANNEL]):
                  print(f"[Logger] Pusher not configured. Skipping {event_name}")
                  return

              timestamp = str(int(time.time()))
              body_data = json.dumps(data_payload)
              body = json.dumps({
                  "name": event_name,
                  "channels": [CHANNEL],
                  "data": body_data
              })
              
              body_md5 = hashlib.md5(body.encode('utf-8')).hexdigest()
              sign_string = f"POST\n/apps/{PUSHER_APP_ID}/events\nauth_key={PUSHER_KEY}&auth_timestamp={timestamp}&auth_version=1.0&body_md5={body_md5}"
              auth_signature = hmac.new(PUSHER_SECRET.encode('utf-8'), sign_string.encode('utf-8'), hashlib.sha256).hexdigest()
              
              params = urllib.parse.urlencode({
                  'auth_key': PUSHER_KEY,
                  'auth_timestamp': timestamp,
                  'auth_version': '1.0',
                  'body_md5': body_md5,
                  'auth_signature': auth_signature
              })
              
              try:
                  conn = http.client.HTTPSConnection(f"api-{PUSHER_CLUSTER}.pusher.com", timeout=3)
                  headers = {'Content-Type': 'application/json'}
                  conn.request("POST", f"/apps/{PUSHER_APP_ID}/events?{params}", body, headers)
                  resp = conn.getresponse()
                  resp.read()
                  conn.close()
              except Exception as e:
                  print(f"[Logger] Pusher Error: {e}")

          if __name__ == "__main__":
               if len(sys.argv) > 1:
                   msg = sys.argv[1]
                   send_to_pusher("log", {"message": msg})
          EOF

      - name: Start Sync
        env:
          PUSHER_APP_ID: ${{ secrets.PUSHER_APP_ID }}
          PUSHER_KEY: ${{ secrets.PUSHER_KEY }}
          PUSHER_SECRET: ${{ secrets.PUSHER_SECRET }}
          PUSHER_CLUSTER: ${{ secrets.PUSHER_CLUSTER }}
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
        run: python3 logger.py "☁️ Request received. Syncing to standard dataset structure..."

      - name: Clone Hugging Face Repo
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          git config --global user.email "bot@maia.api"
          git config --global user.name "Maia Bot"
          git clone --depth 1 https://user:$HF_TOKEN@huggingface.co/datasets/toquereflexo/maia-deep-search hf_repo

      - name: Download Files & Structure (Strict Merge)
        env:
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
          PDF_URL: ${{ github.event.client_payload.pdf_url || inputs.pdf_url }}
          GAB_URL: ${{ github.event.client_payload.gabarito_url || inputs.gabarito_url }}
          MODE: ${{ github.event.client_payload.mode || 'overwrite' }}
        run: |
          cd hf_repo
          mkdir -p "output/$SLUG/files"

          # Function to check and download
          download_strict() {
            local url="$1"
            local fname="$2"
            
            if [ -n "$url" ] && [ "$url" != "null" ]; then
                # STRICT CHECK: If file exists AND mode is NOT overwrite, FAIL.
                if [ -f "output/$SLUG/files/$fname" ] && [ "$MODE" != "overwrite" ]; then
                    echo "::error::CONFLICT: File 'output/$SLUG/files/$fname' already exists. Cannot overwrite in strict mode."
                    exit 1
                fi
                
                echo "Downloading $fname from $url..."
                # Use --fail to exit code 22 on 404/500 errors
                if ! curl -sL --fail -o "output/$SLUG/files/$fname" "$url"; then
                     echo "::error::Download failed (HTTP Error) for $url"
                     exit 1
                fi
                
                # MIME TYPE CHECK
                mime_type=$(file --mime-type -b "output/$SLUG/files/$fname")
                echo "Detected MIME type: $mime_type"
                
                if [[ "$mime_type" != "application/pdf" ]]; then
                    echo "::error::Invalid file type downloaded! Expected application/pdf, got $mime_type. URL: $url"
                    # Cat the file to logs if it's text (likely an error message)
                    if [[ "$mime_type" == text/* ]]; then
                        cat "output/$SLUG/files/$fname"
                    fi
                    rm "output/$SLUG/files/$fname"
                    exit 1
                fi
            else
                echo "Skipping $fname (No URL provided, preserving existing if any)."
            fi
          }

          download_strict "$PDF_URL" "prova.pdf"
          download_strict "$GAB_URL" "gabarito.pdf"

          ls -R "output/$SLUG"

      - name: Update Manifest (Merge Strategy)
        env:
          # Access nested metadata or fallbacks
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
          TITLE: ${{ github.event.client_payload.title || inputs.title }}
          YEAR: ${{ github.event.client_payload.metadata.year || inputs.year }}
          INSTITUTION: ${{ github.event.client_payload.metadata.institution || inputs.institution }}
          PHASE: ${{ github.event.client_payload.metadata.phase || inputs.phase }}

          # Only add entries for what we actually downloaded
          HAS_PDF: ${{ github.event.client_payload.pdf_url != '' && github.event.client_payload.pdf_url != 'null' }}
          HAS_GAB: ${{ github.event.client_payload.gabarito_url != '' && github.event.client_payload.gabarito_url != 'null' }}
        run: |
          cd hf_repo/output/$SLUG

          cat << 'EOF' > update_manifest.py
          import json
          import os
          import sys

          slug = os.environ.get("SLUG")
          title = os.environ.get("TITLE")
          year = os.environ.get("YEAR")
          inst = os.environ.get("INSTITUTION")
          phase = os.environ.get("PHASE")

          has_pdf = os.environ.get("HAS_PDF") == 'true'
          has_gab = os.environ.get("HAS_GAB") == 'true'

          manifest_path = "manifest.json"
          items = []

          # Load existing if available
          if os.path.exists(manifest_path):
              try:
                  with open(manifest_path, 'r', encoding='utf-8') as f:
                      items = json.load(f)
              except:
                  items = []
                  
          # Prepare New Entries
          new_items = []

          if has_pdf:
               new_items.append({
                  "nome": title,
                  "tipo": "Prova",
                  "ano": year,
                  "instituicao": inst,
                  "fase": phase,
                  "link_origem": "manual-upload",
                  "status": "downloaded",
                  "filename": "prova.pdf",
                  "path": f"output/{slug}/files/prova.pdf"
              })

          if has_gab:
               new_items.append({
                  "nome": f"{title} (Gabarito)",
                  "tipo": "Gabarito",
                  "ano": year,
                  "instituicao": inst,
                  "fase": phase,
                  "link_origem": "manual-upload",
                  "status": "downloaded",
                  "filename": "gabarito.pdf",
                  "path": f"output/{slug}/files/gabarito.pdf"
              })

          # Merge: Append new items to list
          # Optional: Check for duplicates in JSON to be safe? 
          # For now, we trust the file check failed the job if physical conflict existed.
          # But for metadata, we just append.

          if not new_items and not os.path.exists(manifest_path):
              # If we have nothing to add and no manifest exists, we probably shouldn't require one?
              # But let's create empty to be safe.
              pass

          items.extend(new_items)

          with open(manifest_path, "w", encoding="utf-8") as f:
              json.dump(items, f, indent=2, ensure_ascii=False)
              
          print(f"Manifest updated. Total items: {len(items)}")
          EOF

          python3 update_manifest.py
          cat manifest.json

      - name: Compute Visual Hashes
        env:
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
        run: |
          (
            echo "Installing dependencies for hashing..."
            sudo apt-get update && sudo apt-get install -y build-essential libcairo2-dev libpango1.0-dev
            npm install pdfjs-dist@3.11.174 canvas@2.11.2
            
            echo "Computing visual hashes..."
            node scripts/compute-hash.js "hf_repo/output/$SLUG"
          ) 2>&1 | python3 logger.py

      - name: Generate Thumbnails
        env:
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
        run: |
          cat << 'EOF' > generate_thumbnails.py
          import os
          import json
          from pdf2image import convert_from_path
          from pathlib import Path

          slug = os.environ.get("SLUG")
          if not slug:
              print("[Thumb] SLUG env var missing.")
              exit(1)

          base_dir = Path(f"hf_repo/output/{slug}")
          thumbs_dir = base_dir / "thumbnails"
          thumbs_dir.mkdir(exist_ok=True)
          manifest_path = base_dir / "manifest.json"

          if manifest_path.exists():
              try:
                  with open(manifest_path, 'r', encoding='utf-8') as f:
                      data = json.load(f)
                  
                  items = data if isinstance(data, list) else data.get('results', [])

                  updated_count = 0
                  for item in items:
                      fname = item.get('filename')
                      if fname and fname.lower().endswith('.pdf'):
                          pdf_path = base_dir / "files" / fname
                          
                          if pdf_path.exists():
                              try:
                                  # Convert first page
                                  images = convert_from_path(str(pdf_path), first_page=1, last_page=1, dpi=150)
                                  if images:
                                      thumb_name = f"{Path(fname).stem}.jpg"
                                      thumb_path = thumbs_dir / thumb_name
                                      images[0].save(thumb_path, 'JPEG', quality=80)
                                      
                                      item['thumbnail'] = f"output/{slug}/thumbnails/{thumb_name}"
                                      updated_count += 1
                                      print(f"[Thumb] Generated: {thumb_name}")
                              except Exception as e:
                                  print(f"[Thumb] Failed for {fname}: {e}")
                  
                  if updated_count > 0:
                      with open(manifest_path, 'w', encoding='utf-8') as f:
                          json.dump(items, f, indent=2, ensure_ascii=False)
                      print(f"[Thumb] Success. Generated {updated_count} thumbnails.")
                  else:
                      print("[Thumb] No thumbnails generated.")

              except Exception as e:
                  print(f"[Thumb] Critical Error: {e}")
          else:
              print(f"[Thumb] Manifest not found at {manifest_path}")
          EOF

          (
            echo "Installing dependencies..."
            sudo apt-get update && sudo apt-get install -y poppler-utils
            pip install pdf2image

            echo "Generating thumbnails..."
            python3 generate_thumbnails.py
          )

      - name: Generate Index (Markdown)
        env:
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
          TITLE: ${{ github.event.client_payload.title || inputs.title }}
        run: |
          cd hf_repo/output/$SLUG
          echo "# $TITLE" > index.md
          echo "" >> index.md
          echo "- [Prova](https://huggingface.co/datasets/toquereflexo/maia-deep-search/resolve/main/output/$SLUG/files/prova.pdf)" >> index.md
          if [ -f "files/gabarito.pdf" ]; then
             echo "- [Gabarito](https://huggingface.co/datasets/toquereflexo/maia-deep-search/resolve/main/output/$SLUG/files/gabarito.pdf)" >> index.md
          fi

      - name: Push to Hugging Face
        env:
          SLUG: ${{ github.event.client_payload.slug || inputs.slug }}
          PUSHER_APP_ID: ${{ secrets.PUSHER_APP_ID }}
          PUSHER_KEY: ${{ secrets.PUSHER_KEY }}
          PUSHER_SECRET: ${{ secrets.PUSHER_SECRET }}
          PUSHER_CLUSTER: ${{ secrets.PUSHER_CLUSTER }}
        run: |
          cd hf_repo

          # LFS Optimization for robustness
          git config --global http.postBuffer 524288000
          git config --global http.maxRequestBuffer 104857600
          git config --global lfs.activitytimeout 300
          git config --global lfs.dialtimeout 300

          git lfs install
          git lfs track "*.pdf" "*.jpg"
          git add .
          git commit -m "Manual upload (Rich Metadata) for $SLUG" || echo "Nothing to commit"
          git push

          # Notify Frontend
          python3 ../logger.py "✅ Cloud sync complete! Files and Thumbnails are live."
